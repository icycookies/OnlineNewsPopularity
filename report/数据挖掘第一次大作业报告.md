## 数据挖掘第一次大作业报告

组长：罗弈桢 2022310868

组员：侯振宇 许若虞

分工：

- 罗弈桢：数据分析、预处理与可视化，消融实验

- 侯振宇：手动实现Logistic Regression算法，针对两个场景进行分析
- 许若虞：实现PCA-KNN、RF、FNN、Naive Bayes算法

### 1.问题描述

本次作业要求从Online News Popularity数据集中，根据文章的特征预测该其热度。根据题意将该问题抽象为一个二分类问题，即给定输入特征$x\in \mathbb{R}^{n}$，训练模型$f:\mathbb{R}^{n}\rightarrow[0,1]$，对文章受欢迎的概率进行预测。为了进一步简化问题，统一采用$g_{0.5}(x)=\begin{cases}1,\ x\ge 0.5\\0, x<0.5\end{cases}$对预测概率进行离散化，得到0/1的是否受欢迎的标签。

我们实现了五个常见的分类模型，分别为Logistic Regression、PCA-KNN、SVM、FNN和Naive Bayes。关于模型 的实现细节和具体表现分别在第3节和第4节中进行详细介绍。

衡量模型的指标包括Accuracy、AUC、F1 score、Precision和Recall。三个指标的具体含义将在第3节中介绍。

### 2.数据分析与预处理

#### 2.1 数据分析与可视化

这部分代码在`preprocessing.ipynb`中。

阅读`OnlineNewsPopularity.names`可知该数据集包括了2013至2015年Meshable网站上发布的39797条新闻，统计了61维特征，其中前两维特征分别为新闻的url和发布时间，后58维特征表示了新闻的某些属性，最后1维特征为转发数。可以发现原始数据已经根据发布时间从前到后进行了排序。根据题意，认为shares>=1400为受欢迎，标签为1，否则标签为0。统计得原始数据共包含39644个样本，其中正样本数量为21154，负样本数量为18490。

各个特征的含义、维度和数值类型如下表所示：

<img src="./feat1.png" alt="image-20221218161751937" style="zoom:50%;" /><img src="./feat2.png" alt="image-20221218162032278" style="zoom:50%;" />

对各个数字类型的特征进行归一化并绘制盒图，通过皮尔逊相关系数和卡方检验分析它们与分享次数的关系，有如下几个结论：
- 数据中存在一个离群点，绝大多数样本的`n_unique_tokens`，`n_non_stop_words`和`n_non_stop_unique_tokens`取值都在$[0,1]$之间，因此三个词条应当反映的是比率数值而不是绝对数值，而某一样本的这三个特征取值分别为701,1042,650，需要剔除，否则会影响归一化的结果；

- 部分特征的数值分布比较极端，如`kw_max_min`，该特征的最大值与平均值相差了2个数量级，且观察盒图可以发现绝大多数样本分布在中间，而少数样本分布在较大或较小的区域，这些特征可能会导致后续模型训练中数值不稳定；
  ![image-20221218164735741](./boxplot.png)

- 存在一些“重要”特征，如是否在周末发布、关键词的分享次数、新闻的极性等，以下列举一部分，并分析`kw_avg_avg`,`global_sentiment_polarity`和`n_tokens_title`的在正负样本上的取值分布；

    | 特征名                    | 皮尔逊相关系数 |
    | ------------------------- | -------------- |
    | Is_weekend                | 0.1598         |
    | data_channel_is_world     | -0.1542        |
    | kw_avg_avg                | 0.1393         |
    | global_sentiment_polarity | 0.1193         |
    | n_tokens_title            | -0.0439        |

    ![featdistri](/Users/luoyizhen/Desktop/课件/数据挖掘2/hw1/OnlineNewsPopularity/report/featdistri.png)

    对于weekday和channel两类特征绘制柱状图，如下所示：<img src="./weekday.png" alt="image-20221218162147056" style="zoom:50%;" />

    <img src="./channel.png" alt="image-20221218162207031" style="zoom:50%;" />

    对于重要特征，它们在正样本与负样本上的取值是存在不同的。此外，这些相关性是可解释的，如周末发布的新闻和与社交媒体、技术等主题相关的新闻更受欢迎，而关于娱乐和世界主题的新闻则不受欢迎；极性较强的新闻更容易被传播；若新闻中包含了一些转发频率更高的关键词，则更受欢迎；标题较短的新闻更受欢迎等；

- 存在一些无用特征，如`n_nonstop_words`（非停用词），样本的取值分布集中在0和0.99以上，观察该特征值为0的新闻可以发现它只有图片和视频，没有文本，而取值大于0.99的则由文本组成，另一方面，该特征与分享次数的皮尔逊相关系数约为0；

进一步地，使用sklearn中实现的PCA和t-SNE方法对特征降至2维并可视化，如下图所示（左为PCA，右为t-SNE，蓝色和橙色的点分别代表正/负样本，由于t-SNE算法运行效率较低，因此只选择了5000个样本做可视化）：

<img src="./dimreduction1.png" alt="image-20221218163919868" style="zoom:50%;" />

可以发现不管采用哪种算法进行降维，正负样本都不是线性可分的，并且正负样本特征的聚类性质不是特别明显，因此使用单个线性分类器或KNN的方法可能无法取得非常理想的结果。

#### 2.2 数据预处理

数据预处理代码在`preprocessing.py`中，主要包括了以下几个部分：

- 离群点剔除；
- 特征归一化，首先对取值范围比较大的特征取对数，接着使用MinMax进行归一化，即对于第i维特征，$x_{j,i}=\frac{x_{j,i}-\min_k{x_{k,i}}}{\max_k{x_{k,i}}-\min_{k}x_{k,i}}$；
- 数据集分割，实现了两种分割策略，分别为按照时间顺序和随机对数据集进行train:test=4:1的分割；

### 3.模型与实验设置

#### 3.1 实现模型简介

本次实验共实现了Logistic Regression, PCA-KNN, Random Forest, FNN, Naive Bayes五个模型，其中Logistic Regression由小组成员自行实现，其余的4个模型均调用了sklearn包中的相应算法。

##### 3.1.1 Logistic Regression算法

Logistic Regression是一个线性分类器模型，Logistic函数本身具有一定的统计学意义，Logistic回归算法的输出可以对应某种边界下，一次试验的可能性。Logistic Regression形式简洁，算力要求小，是0-1两点分类问题的一种经典方法，被广泛应用在流行病学等研究中。

##### 3.1.2 PCA-KNN算法

PCA（主成分分析）是一种输入降维的算法，通过矩阵变换提取输入的主要特征信息，输入为n维数据，输出为k维数据。sklearn包的PCA算法的核心是对原矩阵SVD奇异值分解，保留其k个主特征对的信息。
KNN（k最近邻）算法是一种经典的分类算法，基本原理是将待分类数据的类别取它最近的k个已分类数据点的类别。

##### 3.1.3 RF算法

RF算法是一种集成分类算法，通过一些决策树分类器组成的森林，分别对数据的子集进行分类，然后通过整合这些信息来提升预测的准确性，控制过拟合。

##### 3.1.4 FNN算法

FNN算法是ANN中较简洁的一种，也是应用较为广泛，发展较为成熟的算法。网络中信息单向传播，无反馈信息，故称为前馈神经网络。

##### 3.1.5 Naive Bayes

Naive Bayes算法以概率统计学中贝叶斯原理为基础，并采用了一个常见的基本假定：各特征条件之间相互独立。Naive Bayes算法具有明确的数学原理，算法逻辑较为简洁，在数据集较大、输入矩阵秩较满的情况下有较高的准确率和较低的误判率。本次实验采用的Naive Bayes采取的分布是高斯分布，即认为所有独立变量服从高斯分布。Naive Bayes算法没有需要输入的超参数。

#### 3.2 评价指标简介

本次实验采取的评价指标有Accuracy, AUC, F1 Score, Precision, Recall这5项。
本部分中的符号说明：TP代表正确分类的阳性数据，TN代表正确分类的阴性数据，FP代表错误分类的阳性数据，FN代表错误分类的阴性数据，n代表数据集规模。

- Accuracy（准确率）是分类效果最直观的判据，是所有正确预测的样本的比例。其计算公式为：
  $Accuracy=\frac{TP+TN}{N}$

  在本实验中，由于正负样本分布均匀，因此Accuracy是一个合理的评价指标；

- Precision（精准率）是所有预测为正样本中正确预测的概率，着重关注对正样本的预测是否精确。其计算公式为：
  $Precision=\frac{TP}{TP+FP}$

  在进行新闻推荐时，推送大量用户不感兴趣的新闻会导致用户黏性下降，因此在经过筛选之后的推荐需要考虑到这一指标；

- Recall（召回率）是所有正样本中被捕捉到的概率，着重关注对正样本的捕捉是否充分。其计算公式为：
  $Recall = \frac{TP}{TP+FN}$

  新闻推荐的第一步需要将所有可能受欢迎的新闻筛选出来，此时Recall指标比较重要，推荐系统不能放过任何一个有可能受欢迎的内容；

- F1 Score
  F1 Score是对precision和recall两个指标的综合考虑，取的是这两个指标的调和平均值，以兼顾两个方面。需要注意的是，当Precision和Recall两个指标中出现了退化值（即接近0甚至等于0时），F1 Score指标也会很低。其计算公式为：
  $F1=\frac{2*Precision*Recall}{Precision+Recall}$

  该指标在正负样本不均衡或多分类问题中更加适用，本次实验中虽然有一定的有效性，但也存在问题：当模型预测全0或全1时F1 Score可以达到约2/3，但在我们的实验中绝大多数模型都没有达到这一结果，因此需要综合分析Precision和Recall，以防止某个模型通过预测全1取得具有迷惑性的好结果。

- AUC
  AUC(area under curve)指标，具体是指ROC(Receiver Operating Characteristics)曲线下方的面积，而ROC曲线是TP率-FP率的图像。AUC指标展示了在不同严格程度（即对FP容忍水平）下TP样本的数量，可以较为全面地展现分类的特性，是一个较为健壮的评价指标。AUC指标的取值范围为[0,1]，值越高，代表分类的效果越好。使用该指标时，模型应该输出概率而非离散的预测值。

#### 3.3 超参设置

对于除FNN以外的模型，使用Grid Search搜索模型的最佳超参，具体实现调用了sklearn的`GridSearchCV()`函数，该函数依次遍历所有的超参组合，针对随机分割的训练集进行5-fold验证，以F1 Score作为评价指标进行比较。对于FNN，由于训练较慢且参数组合较多，采用随机搜索方法`RandomizedSearchCV()`，将网格搜索中的遍历改为随机选取超参组合以提高效率。各个模型的超参选择如下（最佳组合用粗体标出）：

- Logistic Regression: {"learning_rate (学习率)" : [0.1, **0.5**, 1.0], "num_iterations (迭代次数)": [500, 1000, **2000**]}
- PCA-KNN: {"n_dimensions (PCA降维数)": [3,5,**7**,10,20], "n_neighbors (KNN邻居数)": [3, 5, **7**, 10, 20]}
- RF: {"n_estimators (决策树个数)": [50, 100, 200, **500**], "max_depth (决策树最大深度)": [5, **10**, 20]}
- FNN: {"activation(激活函数)": [sigmoid, **ReLU**, tanh], batch_size (批大小)": [32, 128, **256**], "learning_rate(学习率)": [**0.001**, 0.005, 0.01], "num_iterations (迭代次数)": [**50**, 100, 200]}
- Naive Bayes：没有需要调整的超参

### 4.实验结果与分析

#### 4.1 Benchmark结果

使用10个随机种子进行实验，并报告了模型各指标的均值和方差，如下所示：

| Model               | Accuracy (%)       | AUC (%)            | F1 Score (%)       | Precision (%)      | Recall (%)         |
| ------------------- | ------------------ | ------------------ | ------------------ | ------------------ | ------------------ |
| Logistic Regression | 65.16$\pm$0.21     | 70.37$\pm$0.22     | 64.80$\pm$0.24     | 62.77$\pm$0.32     | 66.96$\pm$0.67     |
| PCA-KNN             | 53.89$\pm$0.07     | 56.46$\pm$0.06     | 57.83$\pm$0.58     | 51.45$\pm$0.06     | 66.04$\pm$1.59     |
| RF                  | **67.04$\pm$0.13** | **73.76$\pm$0.06** | **67.64$\pm$0.14** | **63.83$\pm$0.12** | **71.93$\pm$0.19** |
| Naive Bayes         | 62.29$\pm$0.00     | 66.29$\pm$0.00     | 57.40$\pm$0.00     | 62.53$\pm$0.00     | 53.04$\pm$0.00     |
| FNN                 | 66.20$\pm$0.40     | 72.21$\pm$0.25     | 66.26$\pm$1.11     | 63.52$\pm$1.21     | 69.43$\pm$3.76     |

五个模型的AUC曲线如下：

![auc](/Users/luoyizhen/Desktop/课件/数据挖掘2/hw1/OnlineNewsPopularity/report/auc.png)

从Accuracy指标进行分析，发现RF结果最好，FNN和Logistic Regression次之，而PCA-KNN的表现最差。RF表现好的原因可能是数据集中的特征具有一定的可解释性且分布不连续，基于决策树的判断条件对数据进行划分能够更好地捕获其中的性质；此外，Logistic Regression可以被看作是使用sigmoid激活函数的一层FNN，因此性能略低于层数更多的FNN，但已经有相当理想的表现；Naive Bayes是纯基于统计学习的方法，因此不受随机因素的影响；PCA-KNN的表现不佳，仅略高于随机预测，发现该模型的Overfit比较严重（该方法在训练集上Accuracy能达到0.7），由之前可视化结果推测可能是PCA降维的特征聚类特性比较差，导致基于最近邻的方法无法推广到未见过的点。

对比各个指标发现除了Naive Bayes之外的各模型的Recall均显著高于Precision，这是由于训练集和测试集中正负样本比例不一致导致的（训练集正样本占54.7%，测试集正样本占47.9%），在训练集上训练的模型更倾向于预测1而非0。

####  4.2 消融实验

为了验证第二节中提到的高相关性特征和无用特征，设计了如下实验：

仅考虑训练集，首先将所有特征按照与标签的皮尔逊相关系数的绝对值从高到低排序，使用前$k$个或后$k$个特征作为输入，下图绘制了逻辑回归模型(Logistic Regression)的Accuracy结果与特征数量$k$的关系。

![ablation](/Users/luoyizhen/Desktop/课件/数据挖掘2/hw1/OnlineNewsPopularity/report/ablation.png)

可以发现随着使用特征数量的增加，模型的准确率呈上升趋势。当特征数量相同时，使用Pearson相关系数较高的特征，模型的预测性能显著更好。

#### 4.3 场景1分析

本场景下，我们选取逻辑回归模型(Logistic Regression)来进行分析。逻辑回归是一个线性模型，一个样本的预测结果来源于多个特征的加权和。其计算公式如下：
$$ y=\sigma(\beta_0 + \beta_1 x_1 +...+\beta_n x_n),
$$
其中$(\beta_1, \beta_2,..., \beta_n)$ 表示n项特征的权重，$\sigma(x)=\frac{1}{1+e^{(-x)}}$为Sigmoid函数。本次实验中输入数据包含58维特征，即n=58。在数据预处理过程中，所有的特征被放缩到[0,1]之间，所以权重可以直接反映该项特征对最终预测的贡献度。从各项特征的权重大小中，我们可以找出受欢迎新闻的特征以及影响新闻受欢迎性的积极和消极因素。以下是部分特征的权重。从中可以观察到，"self_reference_max_shares"、"kw_max_min"是让新闻受欢迎的特征，情感偏极端的新闻和社交媒体相关的内容也比较容易传播。相反地，特别积极正面的情感"avg_positive_polarity"、"global_rate_positive_words"反而不容易传播，并且周二、周三这些工作日发表的文章也比较难成为受欢迎的文章，引用太多其他新闻容易分走读者注意力等等。

```
 self_reference_max_shares	1.3030038017863100
 kw_max_min	1.2280743774325800
 global_sentiment_polarity	0.979687172461446
 avg_negative_polarity	0.8002079479412650
 data_channel_is_socmed	0.7909692905356790
 title_sentiment_polarity	0.7330151654720210
 kw_avg_avg	0.7088845154627420
 weekday_is_saturday	0.5742165612955550
 num_videos	0.5523079709757170
 kw_max_avg	0.5275130109568780
 num_imgs	0.5125231996034780
 kw_min_avg	0.46497099069444200
 n_tokens_title	0.4576180295863530
 ...
 weekday_is_tuesday	-0.6490272016558530
 weekday_is_wednesday	-0.6545017043010620
 data_channel_is_entertainment	-0.6926785231408350
 kw_max_max	-0.8067340188886200
 global_rate_positive_words	-0.9334613180532240
 avg_positive_polarity	-0.9401039126134160
 num_self_hrefs	-2.049860647092770
```

####  4.3 场景2分析

首先对发布时间与特征的关系进行研究，按照各个样本的`time_delta`值分为5类，从每一类中随机选取1000个样本，用PCA和t-SNE方法将特征降维并可视化如下：

![image-20221218205940674](./dimreduction2.png)

可以发现发布时间与特征存在一定关联，如发布时间较早的新闻（`time_delta`在$[582,732]$之间）的PCA降维结果偏向于分布在下半平面，而t-SNE的降维结果则呈现出比较明显的聚类特征。

下表展示了不同时刻训练数据对模型在测试集性能的影响。我们分别选取了距离测试集时间最近的数据和时间最远的数据进行实验，同时也探究了不同训练集大小的影响。从下表可以看出：
- 发布时间最早的新闻与最新发布的新闻作为训练集对模型性能的影响很大。在相同训练数据大小下，使用最新发布的新闻作为训练数据比使用时间较早的数据性能要高出7%～10%。这说明新闻具有相似的实效性，发布时间相近的新闻更倾向于拥有类似的特征。
- 另一方面，我们比较了不同训练集大小对模型性能的影响，即分别选用时间最早的1%、10%数据，和最新发布的1%、10%、50%数据来分析。可以看到，增大训练集的规模可以带来模型性能的提升。将训练从1%提升至10%数据时，使用时间最早（A）部分和最新发布（B）训练得到的模型性能分别有大约2%和5%左右的提升。当继续增大训练集大小时，A部分增加的是发布时间更靠后的数据，B增加的是发布更早的数据，所以使用最新发布50%相对于使用最新发布10%的数据训练模型性能几乎没有提升。所以我们可以得出，当训练数据与测试数据分布较相似时，适度增大训练数据能够在一定范围内提升模型性能。如果增大训练集的数据是无用的数据，则对模型最终性能影响不大。

| 训练数据 | Accuracy | AUC  | F1   |
| ---------- | -------- | ---- | ---- |
| 时间最早 1% | 0.5175 | 0.5219 | 0.5063 |
| 时间最早 10% | 0.5375 | 0.5419 | 0.5200 |
| 时间最早 50% | 0.6134 | 0.6064 | 0.5212 |
| 最新发布 1% | 0.5815 | 0.5851 | 0.6035 |
| 最新发布 10% | 0.6376 | 0.6404 | 0.6512 |
| 最新发布 50% | 0.6411 | 0.6434 | 0.6509 |

我们也对比了在整个训练集中随机采样一定比例的数据用于训练，评估这种情境下训练集大小的影响。结果如下图所示。可以看到，当不考虑时间因素，随机对数据集进行采样时，增大训练集能带来模型性能提升。当增大到一定比例时(<0.5)，继续增大训练集带来的提升并不显著。
<img src="./split_ratio.png" style="zoom:50%;centering:;" />


